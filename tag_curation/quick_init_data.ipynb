{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# pip install py7zr\r\n",
        "# pip install transformers\r\n",
        "# pip install torch\r\n",
        "# pip install beautifulsoup4\r\n"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1677185553186
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "os.chdir(\"data\")"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677185555411
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_subject(subject):\r\n",
        "    url = \"https://archive.org/download/stackexchange/{}.stackexchange.com.7z\".format(subject)\r\n",
        "    filename = \"{}.stackexchange.com.7z\".format(subject)\r\n",
        "\r\n",
        "    response = requests.get(url)\r\n",
        "    with open(filename, \"wb\") as f:\r\n",
        "        f.write(response.content)\r\n",
        "\r\n",
        "    return filename\r\n",
        "\r\n",
        "def unzip(zip_filename):\r\n",
        "    # unzip .7z file\r\n",
        "    import py7zr\r\n",
        "\r\n",
        "    # Specify the name of the input 7z file and the output folder\r\n",
        "    input_file = zip_filename\r\n",
        "    output_folder = zip_filename[:-4]\r\n",
        "\r\n",
        "    # Make sure the output folder exists\r\n",
        "    os.makedirs(output_folder, exist_ok=True)\r\n",
        "\r\n",
        "    # Open the 7z file and extract all its contents to the output folder\r\n",
        "    with py7zr.SevenZipFile(input_file, 'r') as archive:\r\n",
        "        archive.extractall(output_folder)\r\n",
        "    \r\n",
        "    return output_folder\r\n",
        "\r\n",
        "def extract_dataset(subject_folder, subject, csv_filename):\r\n",
        "    # read posts.xml\r\n",
        "    import xml.etree.ElementTree as ET\r\n",
        "    import csv\r\n",
        "\r\n",
        "    # Parse the XML file\r\n",
        "    tree = ET.parse(subject_folder + '/Posts.xml')\r\n",
        "    root = tree.getroot()\r\n",
        "\r\n",
        "    # Open the output CSV file\r\n",
        "    with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:\r\n",
        "        writer = csv.writer(csvfile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\r\n",
        "        \r\n",
        "        # Write the header row\r\n",
        "        writer.writerow(['id', 'title', 'body', 'tags'])\r\n",
        "        \r\n",
        "        # Loop over all the rows in the XML file\r\n",
        "        for row in root.findall('row'):\r\n",
        "            # Extract the relevant fields from the XML element\r\n",
        "            post_id = row.get('Id')\r\n",
        "            title = row.get('Title')\r\n",
        "            body = row.get('Body')\r\n",
        "            tags = row.get('Tags')\r\n",
        "            \r\n",
        "            # Write the row to the CSV file\r\n",
        "            writer.writerow([post_id, title, body, tags])\r\n",
        "\r\n",
        "    return csv_filename\r\n"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677185559874
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\r\n",
        "\r\n",
        "subjects=[\"datascience\", \"money\"] #, \"music\", \"politics\", \"raspberrypi\", \"scifi\", \"skeptics\", \"unix\"]\r\n",
        "\r\n",
        "for subject in subjects:\r\n",
        "    zip_filename = download_subject(subject)\r\n",
        "    subject_folder = unzip(zip_filename)\r\n",
        "    csv_filename = subject + '_posts.csv'\r\n",
        "    extract_dataset(subject_folder, subject, csv_filename)"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677179838621
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df['tags'].str.split('><').apply(lambda x: [tag.strip(\"<> \") for tag in x if tag.strip()] if isinstance(x, list) else [])\r\n",
        "import pandas as pd, numpy as np\r\n",
        "from bs4 import BeautifulSoup\r\n",
        "import re\r\n",
        "\r\n",
        "# Define a function to extract text content from HTML tags\r\n",
        "def pre_process(text):\r\n",
        "    if not isinstance(text, str) or text.strip() == '':\r\n",
        "        return ''\r\n",
        "    text = BeautifulSoup(text).get_text()\r\n",
        "    # fetch alphabetic characters\r\n",
        "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\r\n",
        "    # convert text to lower case\r\n",
        "    text = text.lower()\r\n",
        "    # split text into tokens to remove whitespaces\r\n",
        "    tokens = text.split()\r\n",
        "    return \" \".join(tokens)\r\n",
        "    #   soup = BeautifulSoup(html, 'html.parser')\r\n",
        "    # return soup.get_text()"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677186395293
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploring only the datascience_posts here:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\r\n",
        "\r\n",
        "# csv name\r\n",
        "csv_filename = \"datascience\" + '_posts.csv'\r\n",
        "\r\n",
        "# Load CSV file into Pandas DataFrame\r\n",
        "df = pd.read_csv(csv_filename)\r\n",
        "\r\n",
        "# Create content and labels lists\r\n",
        "content = df['body'].apply(pre_process).tolist()\r\n",
        "labels = df['tags'].str.split('><').apply(lambda x: [tag.strip(\"<> \") for tag in x if tag.strip()] if isinstance(x, list) else [])\r\n",
        "\r\n",
        "# Print the first content and labels for verification\r\n",
        "print(content[0])\r\n",
        "print(labels[0])\r\n",
        "\r\n",
        "# Split data into training and testing sets\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "train_content, test_content, train_labels, test_labels = train_test_split(content, labels, test_size=0.2, random_state=42)\r\n",
        "\r\n",
        "# Print the number of samples in each set\r\n",
        "print('Number of training samples:', len(train_content))\r\n",
        "print('Number of testing samples:', len(test_content))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/tmp/ipykernel_91751/1696799192.py:10: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n  text = BeautifulSoup(text).get_text()\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "i ve always been interested in machine learning but i can t figure out one thing about starting out with a simple hello world example how can i avoid hard coding behavior for example if i wanted to teach a bot how to avoid randomly placed obstacles i couldn t just use relative motion because the obstacles move around but i don t want to hard code say distance because that ruins the whole point of machine learning obviously randomly generating code would be impractical so how could i do this\n['machine-learning']\nNumber of training samples: 59461\nNumber of testing samples: 14866\n"
        }
      ],
      "execution_count": 39,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677189297137
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bert direction...\r\n",
        "# import torch\r\n",
        "# from sklearn.preprocessing import MultiLabelBinarizer\r\n",
        "# from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\r\n",
        "\r\n",
        "\r\n",
        "# # Encode the tags as one-hot vectors\r\n",
        "# mlb = MultiLabelBinarizer()\r\n",
        "# y_train = mlb.fit_transform(train_labels)\r\n",
        "\r\n",
        "# # Tokenize the posts using the BERT tokenizer\r\n",
        "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\r\n",
        "\r\n",
        "# def tokenize_function(c):\r\n",
        "#     return tokenizer(c, padding=\"max_length\", truncation=True)\r\n",
        "\r\n",
        "# X_train = tokenizer.batch_encode_plus(\r\n",
        "#         train_content,\r\n",
        "#         return_attention_mask=True,\r\n",
        "#         return_token_type_ids=True,\r\n",
        "#         pad_to_max_length=True,\r\n",
        "#         padding='max_length',\r\n",
        "#         truncation=True\r\n",
        "\r\n",
        "#     )\r\n",
        "    \r\n",
        "    \r\n",
        "# # Define the BERT model for sequence classification\r\n",
        "# model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(mlb.classes_))\r\n",
        "\r\n",
        "# # Define the training arguments and trainer\r\n",
        "# training_args = TrainingArguments(\r\n",
        "#     output_dir='./results',\r\n",
        "#     num_train_epochs=3,\r\n",
        "#     per_device_train_batch_size=16,\r\n",
        "#     per_device_eval_batch_size=64,\r\n",
        "#     warmup_steps=500,\r\n",
        "#     weight_decay=0.01,\r\n",
        "#     logging_dir='./logs',\r\n",
        "#     logging_steps=10,\r\n",
        "#     evaluation_strategy='steps',\r\n",
        "#     eval_steps=50,\r\n",
        "#     load_best_model_at_end=True\r\n",
        "# )\r\n",
        "\r\n",
        "# trainer = Trainer(\r\n",
        "#     model=model,\r\n",
        "#     args=training_args,\r\n",
        "#     train_dataset=torch.utils.data.TensorDataset(torch.tensor(X_train['input_ids']), torch.tensor(X_train['attention_mask']), torch.tensor(y_train))\r\n",
        "# )\r\n",
        "\r\n",
        "# # Train the model\r\n",
        "# trainer.train()\r\n",
        "\r\n",
        "# # Save the model and tokenizer\r\n",
        "# model.save_pretrained('./model')\r\n",
        "# tokenizer.save_pretrained('./model')"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677193614669
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": 95,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677192700058
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK V2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}